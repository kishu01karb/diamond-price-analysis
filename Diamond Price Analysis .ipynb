{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e843ebf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIAMOND PRICE ANALYSIS WITH MACHINE LEARNING\n",
    "#Importing our tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder #It converts categorical text values into numeric values\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#Predicts output using a straight-line relationship between input and output.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#Predicts output by combining predictions from multiple decision trees to improve accuracy.\n",
    "#To compare simple and complex models and choose the best-performing one\n",
    "from sklearn. metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da3b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#makeing plots look preety\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] =(10,6) #is used to set a consistent and readable size for all plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f65ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP-1\n",
    "#LOAD DATA\n",
    "df = pd.read_csv(\"C:/Users/krish/vscode/ML projects/Diamond Price Analysis Prediction/diamonds.csv\")\n",
    "\n",
    "#show the first few diamonds\n",
    "print(\"First 5 diamonds in our dataset\")\n",
    "print(df.head())\n",
    "\n",
    "#check the shape \n",
    "print(f\"We have {len(df)} diamonds with {len(df.columns)} features!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487942cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 2 eXPLORE THE DATA\n",
    "print(\"Statistical summary:\")\n",
    "print(df.describe())\n",
    "#Is used to generate descriptive statistics that summarize the distribution, central tendency, and spread of numerical features in the dataset.\n",
    "\n",
    "#check for missing values\n",
    "print(\"\\n Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#check datatypes\n",
    "print(\"\\n Data types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf81a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 3 VISUALIZE THE PATTERNS\n",
    "\n",
    "#1. HOW DOES CARAT (SIZE) AFFECT THE PRICE?\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(df['carat'],df['price'],alpha = 0.3, c='steelblue')\n",
    "plt.xlabel('Carat (Size)', fontsize=12)\n",
    "plt.ylabel('Price($)' , fontsize=12)\n",
    "plt.title('Effect of Diamond Size on Prices', fontsize=14,fontweight ='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ba11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The scatter plot shows a strong positive relationship between diamond carat and price. However, the relationship is non-linear, with significant price variation at the same carat value due to other quality factors like cut, color, and clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f781171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.PRICE DISTRIBUTION ACROSS DIFFERENT CUTS\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=df,x='cut',y='price',palette='Set2')\n",
    "plt.xlabel('Cut Quality', fontsize=12)\n",
    "plt.ylabel('Price($)', fontsize=12)\n",
    "plt.title('How Cut Quality Affects the Price', fontsize=14,fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8f2e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This boxplot shows that better cut diamonds usually have higher prices, but there is a wide price range in every cut because other factors also affect the price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ea7db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.PRICE BY COLOR GRADE\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=df,x='color',y='price',palette='viridis')\n",
    "plt.xlabel('Color Grade', fontsize=12)\n",
    "plt.ylabel('Price($)',fontsize=12)\n",
    "plt.title('Diamond color VS Price($)',fontsize=14,fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Middle line â†‘ â†’ more expensive\n",
    "#Box tall â†’ price varies\n",
    "#Dots â†’ rare expensive diamonds(outliers)\n",
    "#Color affects price, but it does not decide price alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7883a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. CORREALATION HEATMAP\n",
    "plt.figure(figsize=(10,8))\n",
    "numeric_cols= df.select_dtypes(include=[np.number]).columns\n",
    "#Selects only numeric columns from the dataset\n",
    "correalation = df[numeric_cols].corr()\n",
    "#Calculates correlation between numeric features\n",
    "sns.heatmap(correalation,annot=True,cmap='coolwarm',center=0)\n",
    "plt.title('Feature Correaltion Map', fontsize=14,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f8dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The correlation heatmap shows that carat has the strongest positive relationship with price, while depth and table have very weak influence. It also reveals multicollinearity among carat and the physical dimensions, which justifies using tree-based models like Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7845344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP4:PREAPARE THE DATA \n",
    "#Remove any unamed index column if it exits\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df= df.drop('Unnamed: 0', axis=1)  #axis=1 means column\n",
    "    \n",
    "#Encode categorical varaibles(cut,color,clarity)\n",
    "#we convert text categories into numbers the model can understand\n",
    "\n",
    "label_encoder={}\n",
    "categorical_columns =['cut','color','clarity']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le=LabelEncoder()\n",
    "    df[col+ '_encoded'] = le.fit_transform(df[col])\n",
    "    label_encoder[col]=le\n",
    "    print(f\"Encoded {col}: {df[col].unique()} -> {df[col+ '_encoded'].unique()}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e05bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select features for our model\n",
    "feature_columns =['carat','cut_encoded','color_encoded','clarity_encoded','depth','table','x','y','z']\n",
    "X=df[feature_columns]  #Input Features\n",
    "y=df['price']  # taregt (what we predict)\n",
    "print(f\"\\n Ready ! we have {len(feature_columns)} features to predict price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0daac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT THE DATA\n",
    "#80% for training ,20% for testing\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "    X,y, test_size=0.2,random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: len{X_train} diamonds\")\n",
    "print(f\"Testing set: len{X_test} diamonds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1871b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 6: TRAIN MODEL #1 LINEAR REGRESSION\n",
    "#create and train the model\n",
    "print(\"Training Linear regression model...\")\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train,y_train)\n",
    "\n",
    "#make predictions\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "#evaluate\n",
    "#Average error in prediction\n",
    "mae_lr = mean_absolute_error(y_test,y_pred_lr)\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test,y_pred_lr))#Large errors are punished more here.\n",
    "r2_lr= r2_score(y_test,y_pred_lr)#Tells how much price variation the model explains\n",
    "\n",
    "print(\"\\n Linear Regression Results:\")\n",
    "print(f\" MAE (average error): ${mae_lr}\")\n",
    "print(f\" RMSE (root mean sqaured error): ${rmse_lr}\")\n",
    "print(f\" RÂ² Score: {r2_lr:.4f} ({r2_lr*100:.2f}% varaince explained) \")\n",
    "\n",
    "#show which features matter most\n",
    "\n",
    "feature_importance = pd.DataFrame(\n",
    "{\n",
    "    'Feature':feature_columns,\n",
    "    'Importance': lr_model.coef_\n",
    "}\n",
    ").sort_values('Importance',ascending=False)\n",
    "print(\"\\n Most Important Features:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1f666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot feature importance\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(feature_importance['Feature'],feature_importance['Importance'], color='forestgreen')\n",
    "plt.xlabel('Importance',fontsize=12)\n",
    "plt.title('Feature Matter most', fontsize=14,fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29555636",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TRAIN MODEL #2 RANDOM FOREST\n",
    "#Create and train the model\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_model =RandomForestRegressor(\n",
    "    n_estimators = 100,\n",
    "    random_state= 42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train,y_train)\n",
    "#make predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "#evaluate\n",
    "mae_rf = mean_absolute_error(y_test,y_pred_rf)\n",
    "rmse_rf =np.sqrt(mean_squared_error(y_test,y_pred_rf))\n",
    "r2_rf = r2_score(y_test,y_pred_rf)\n",
    "\n",
    "print(\"\\n Random Forest Results:\")\n",
    "print(f\" MAE avg error: $ {mae_rf:.2f}\")\n",
    "print(f\" RMSE root ${rmse_rf:.2f}\")\n",
    "print(f\" RÂ² score:{r2_rf:4f} ({r2_rf*100:.2f})% variance explained \")\n",
    "      \n",
    "#feature importance from random forest\n",
    "feature_importance_rf =pd.DataFrame({\n",
    "    'Feature':feature_columns,\n",
    "    'Importance':rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending =False)\n",
    "print(\"\\n Feature Importance(random forest):\")\n",
    "print(feature_importance_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddaf873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot feature importance\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(feature_importance_rf['Feature'],feature_importance_rf['Importance'], color='forestgreen')\n",
    "plt.xlabel('Importance',fontsize=12)\n",
    "plt.title('Feature Matter most', fontsize=14,fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f36aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(lr_model, \"linear_regression_model.pkl\")\n",
    "joblib.dump(rf_model, \"random_forest_model.pkl\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "\n",
    "print(\"Models saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac1a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 8: COMPARE MODELS\n",
    "#create comparison\n",
    "\n",
    "comparison =pd.DataFrame({\n",
    "    'Model':['Linear Regression','Random Forest'],\n",
    "    'MAE':[mae_lr,mae_rf],\n",
    "    'RMSE':[rmse_lr,rmse_rf],\n",
    "    'RÂ² Score':[r2_lr,r2_rf]\n",
    "})\n",
    "\n",
    "print(\"\\n Model Comparison\")\n",
    "print(comparison.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d37b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise actual vs predicted prices\n",
    "#creates a figure with two side by side plots to compare two models\n",
    "fig,axes = plt.subplots(1,2, figsize =(15,6))\n",
    "\n",
    "#linear regression\n",
    "#plots actual vs predicted prices\n",
    "axes[0].scatter(y_test,y_pred_lr,alpha =0.5, c='steelblue')\n",
    "#Draws the perfect prediction line for reference.\n",
    "axes[0].plot([y_test.min(),y_test.max()],[y_test.min(),y_test.max()],'r--',lw=2)\n",
    "axes[0].set_xlabel('Actual price($)', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted Price($)', fontsize=12)\n",
    "axes[0].set_title('Linear Regression Predictions', fontsize=12,fontweight='bold')\n",
    "\n",
    "#Random Forest\n",
    "axes[1].scatter(y_test, y_pred_rf, alpha=0.5, c='forestgreen')\n",
    "axes[1].plot([y_test.min(), y_test.max()],[y_test.min(),y_test.max()],'r--',lw=2)\n",
    "axes[1].set_xlabel('Actual Price($)', fontsize=12)\n",
    "axes[1].set_ylabel('Predicted Price($)' ,fontsize=12)\n",
    "axes[1].set_title('Random Forest Predictions', fontsize=12,fontweight='bold')\n",
    "\n",
    "#Adjusts spacing so plots donâ€™t overlap.\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n The red line = perfect predictions.closer points = better model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8394d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "#STEP 9: MAKE PREDICTIONS ON NEW DIAMONDS \n",
    "\n",
    "import streamlit as st\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    lr_model= joblib.load( \"linear_regression_model.pkl\")\n",
    "    rf_model=joblib.load(\"random_forest_model.pkl\")\n",
    "    label_encoder=joblib.load( \"label_encoder.pkl\")\n",
    "    return lr_model,rf_model, label_encoder\n",
    "\n",
    "lr_model, rf_model, label_encoder = load_model()\n",
    "\n",
    "def predict_diamond_price(carat,cut,color,clarity,depth,table,x,y,z):\n",
    "    \"\"\" \n",
    "    Predict the price of a diamond based on its characteristics\n",
    "    \"\"\"\n",
    "    \n",
    "    # encode the categorical features\n",
    "    cut_encoded = label_encoder['cut'].transform([cut])[0]\n",
    "    color_encoded = label_encoder['color'].transform([color])[0]\n",
    "    clarity_encoded = label_encoder['clarity'].transform([clarity])[0]\n",
    "    \n",
    "    #create feature  array\n",
    "    features =np.array([[carat,cut_encoded,color_encoded,clarity_encoded,depth,table,x,y,z]])\n",
    "    \n",
    "    #predict with both models\n",
    "    price_lr = lr_model.predict(features)[0]\n",
    "    price_rf = rf_model.predict(features)[0]\n",
    "    avg_price = (price_lr + price_rf)/2\n",
    "    \n",
    "    \n",
    "    st.subheader(f\"\\n Diamond charcteristics:\")\n",
    "    st.write(f\" \\nCarat : {carat}, Cut:{cut},Color:{color},Clarity:{clarity},DepthL{depth},Table:{table},X:{x},Y:{y},Z:{z}\")\n",
    "    st.subheader(f\"\\n Predicted Prices:\")\n",
    "    st.write(f\"  Linear Regression: $ {price_lr:.2f}\")\n",
    "    st.write(f\"  Random Forest:     $ {price_rf:.2f}\")\n",
    "    st.write(f\"  Average Prediction:$ {(price_lr + price_rf)/2:.2f}\")\n",
    "    \n",
    "    return avg_price\n",
    "\n",
    "st.title(\"ðŸ’Ž Diamond Price Predictor\")\n",
    "\n",
    "carat = st.number_input(\"Carat\",min_value=0.01,step=0.01)\n",
    "cut = st.selectbox(\"Cut\", label_encoder['cut'].classes_)\n",
    "color =st.selectbox(\"Color\", label_encoder['color'].classes_)\n",
    "clarity =st.selectbox(\"Clarity\", label_encoder['clarity'].classes_)\n",
    "depth = st.number_input(\"Depth\",min_value=0.0,step=0.1)\n",
    "table= st.number_input(\"Table\",min_value=0.0,step=0.1)\n",
    "x= st.number_input(\"X(length in mm), min_value=0.0\",step=0.01)\n",
    "y= st.number_input(\"Y(length in mm), min_value=0.0\",step=0.01)\n",
    "z= st.number_input(\"Z(length in mm), min_value=0.0\",step=0.01)\n",
    "\n",
    "if st.button(\"Predict Price\"):\n",
    "    predict_diamond_price(carat,cut,color ,clarity,depth,table,x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba0e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7b5cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it out!\n",
    "predicted_price = predict_diamond_price(\n",
    "    carat=1.0,\n",
    "    cut='Ideal',\n",
    "    color='E',\n",
    "    clarity='VS1',\n",
    "    depth=61.5,\n",
    "    table=55,\n",
    "    x=6.4,\n",
    "    y=6.5,\n",
    "    z=4.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5342731f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
